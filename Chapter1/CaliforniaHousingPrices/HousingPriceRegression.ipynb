{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Price prediction on California's coast** #\n",
    "\n",
    "Elaborate a model that enables prediciton of median housing prices per block in california.\n",
    "\n",
    "---\n",
    "\n",
    "## **Frame the problem** ##\n",
    "Outputs will be fet to another ML algorithm evaluating if investing in a California's area is worth. It is really important to get accurate prices.\n",
    "A full dataset of california median prices per block is given. It includes median price per block + many other metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Buisness objective** ###\n",
    "Build a ML algorithm to determine areas that are worth investing in. This restricts to California.\n",
    "\n",
    "---\n",
    "\n",
    "### **Use case** ###\n",
    "Outputs will be fet to another ML algorithm evaluating if investing in a California's area is worth.\n",
    "\n",
    "---\n",
    "\n",
    "### **Current solutions?** ###\n",
    "Manual evaluation by a team of experts. If price data does not exists, it is estimated using complex rules. Current precision us +- 30%\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem framing** ###\n",
    "- Clear supervised problem\n",
    "- Batch learning\n",
    "- Multiple, univariate Regression problem\n",
    "\n",
    "---\n",
    "\n",
    "### **How to measure performance?** ###\n",
    "Norm : L2 or L1. Depends on outliers\n",
    "$$RMSE(X,h) = \\sqrt{\\frac{1}{m_i}\\sum_{i=1}^m(h(X_i)-y_i)^2}$$\n",
    "$$MAE(X,h) = \\frac{1}{m_i}\\sum_{i=1}^m|h(X_i)-y_i|$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Is performance measure aligned with buisness objective?** ###\n",
    "Yes as it will allow to know whether we fall under the 30% average error mark.\n",
    "\n",
    "---\n",
    "\n",
    "### **Minimum performance for production** ###\n",
    "Fall under the 30% error mark \n",
    "\n",
    "---\n",
    "\n",
    "### **Comparable or existing solutions** ###\n",
    "\n",
    "None, for exercice purpose\n",
    "\n",
    "---\n",
    "\n",
    "### **Human expertise available?** ###\n",
    "\n",
    "The experts already working to evaluate housing prices.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to solve problem manually** ###\n",
    "\n",
    "Ask the experts\n",
    "\n",
    "---\n",
    "\n",
    "### **List assumptions** ###\n",
    "\n",
    "Currently, we assume the downstream algorithm will use the prices as a continuous value. If for instance it was a category (*low price, medium price, high price*), the precision is less important. Only the category.\n",
    "==> The problem becomes a **classification task**\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluate assumptions** ###\n",
    "\n",
    "For exercice purpose, we assume the task is indeed a regression.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Get the data** ##\n",
    "\n",
    "### **What data and how much?** ###\n",
    "We need the california district housing prices from the SatLib dataset\n",
    "\n",
    "---\n",
    "\n",
    "### Where to get the data? ###\n",
    "\n",
    "---\n",
    "\n",
    "### How much space will the data take ###\n",
    "\n",
    "---\n",
    "\n",
    "### Legal obligations ###\n",
    "\n",
    "---\n",
    "\n",
    "### get authorizations ###\n",
    "\n",
    "---\n",
    "\n",
    "### Create a workspace ###\n",
    "\n",
    "---\n",
    "\n",
    "### Get the data ###\n",
    "\n",
    "---\n",
    "\n",
    "### Convert the data without changing it ###\n",
    "\n",
    "---\n",
    "\n",
    "### Anonimize / protect the data ###\n",
    "\n",
    "---\n",
    "\n",
    "### Check size & type ###\n",
    "\n",
    "---\n",
    "\n",
    "### Sample a test set and never look at it ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data ##\n",
    "\n",
    "### Create a copy ###\n",
    "\n",
    "### Create a notebook to recode exploration ###\n",
    "\n",
    "### Study each attribute ###\n",
    "\n",
    "#### Name ####\n",
    "#### Type ####\n",
    "#### Missing values (%) ####\n",
    "#### Noisiness ####\n",
    "#### Usefulness ####\n",
    "#### Distribution ####\n",
    "\n",
    "### If supervised : what attribute? ###\n",
    "\n",
    "### Visualise the data ###\n",
    "\n",
    "### Explore correlations ###\n",
    "\n",
    "### How to solve manually ###\n",
    "\n",
    "### Study promising transformations to apply before ###\n",
    "\n",
    "### Extra data required? ###\n",
    "\n",
    "### Document what has been learned ###\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data ##\n",
    "\n",
    "### Clean the data ###\n",
    "\n",
    "#### Remove outliers? ####\n",
    "#### Fill missing values or drop columns / rows ####\n",
    "\n",
    "### Select useful features (drop some?) ###\n",
    "\n",
    "### Feature engineering? ###\n",
    "#### Discretize continuous ####\n",
    "#### Decompose ####\n",
    "#### Add promising transformations ####\n",
    "#### Aggregate features into new ones ####\n",
    "\n",
    "### Scale features ###\n",
    "#### Standardize or normalize ####\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortlist models ##\n",
    "\n",
    "### Try and train many quick and dirty models (linear, Bayes, SVM, neural nets, random forests, etc...) ###\n",
    "\n",
    "### Measure performance (use N-folds cross validation) ###\n",
    "\n",
    "### Analize significant variables for each model ###\n",
    "\n",
    "### Analyze errors models make and what data would a human need to avoid these? ###\n",
    "\n",
    "### Quick round of feature selection / engineering ###\n",
    "\n",
    "### Quickly iterate the previous steps (one or two times) ###\n",
    "\n",
    "### Select a few models (3 to 5) preferring models that make different types of errors ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune ##\n",
    "\n",
    "### Fine tune hyperparameters using cross-validation ###\n",
    "- Treat data transforms as hyperparameters especially if not sure about them\n",
    "- Unless very few hyperparameters, prefer random search over grid search. If training is long, use optimizations\n",
    "\n",
    "### Try running models together (often gives better results) ###\n",
    "\n",
    "### Once confindent, validate the model against the test set ###\n",
    "\n",
    "### Measure performance (use N-folds cross validation) ###\n",
    "\n",
    "### Analize significant variables for each model ###\n",
    "\n",
    "### Analyze errors models make and what data would a human need to avoid these? ###\n",
    "\n",
    "### Quick round of feature selection / engineering ###\n",
    "\n",
    "### Quickly iterate the previous steps (one or two times) ###\n",
    "\n",
    "### Select a few models (3 to 5) preferring models that make different types of errors ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1457b87cac6d4aa1774f75f4105ee9216ef3309c69311af26acf73a88761189"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
